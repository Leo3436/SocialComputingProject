{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PROGETTO SOCIAL COMPUTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENTI: Marco Tateo, Leonardo Scandino, Leo Baric, Matteo Palomba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impostazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import *\n",
    "from pyvis.network import Network\n",
    "from networkx.algorithms.approximation import clique\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from scipy.stats import pearsonr, kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"****\"\n",
    "api_secret = \"****\"\n",
    "access_token = \"****\"\n",
    "access_secret = \"****\"\n",
    "bearer_token = \"****\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "if(api.verify_credentials):\n",
    "    print ('Authentication completed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "def read_json(path):\n",
    "    if os.pakendalltaupath):\n",
    "        with open(path, \"r\", encoding=\"utf8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scaricate utenti followers (api.followers) e utenti following (api.friends) di questi cinque account (i dati numerici potrebbero subire minime variazioni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = [\"@KevinRoitero\"]     #nel array prof si possono mettere tutti i prof per scaricare i follower di tutti e cinque i prof automaticamente\n",
    "followers = {}               #abbiamo diviso il lavoro per velocizzare il processo \n",
    "\n",
    "for user in prof:\n",
    "    \n",
    "    print(f\"Processing User {user}\")\n",
    "    \n",
    "    followers_of_user = [] \n",
    "    \n",
    "    for item in tweepy.Cursor(\n",
    "        api.followers, \n",
    "        screen_name=user, \n",
    "        skip_status=True, \n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        \n",
    "        json_data = item._json\n",
    "        \n",
    "        found_follower = {}\n",
    "        found_follower[\"id\"] = json_data[\"id\"]\n",
    "        found_follower[\"name\"] = json_data[\"name\"]\n",
    "        found_follower[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "        found_follower[\"location\"] = json_data[\"location\"]\n",
    "        \n",
    "        if found_follower not in followers_of_user:\n",
    "            followers_of_user.append(found_follower)\n",
    "            \n",
    "    followers = followers_of_user\n",
    "    print(f\"Found {len(followers)} followers for user {user}\")\n",
    "    serialize_json(f\"{data_folder}/Follower\", f\"{user}1_followers.json\", followers) #salva in un file .json i follower del prof in input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = [\"@KevinRoitero\"]   #nel array prof si possono mettere tutti i prof per scaricare i followings di tutti e cinque i prof automaticamente\n",
    "followings = {}             #abbiamo diviso il lavoro per velocizzare il processo\n",
    "\n",
    "for user in prof:\n",
    "    \n",
    "    print(f\"Processing User {user}\")\n",
    "    \n",
    "    followings_of_user = [] \n",
    "    \n",
    "    for item in tweepy.Cursor(\n",
    "        api.friends, \n",
    "        screen_name=user, \n",
    "        skip_status=True, \n",
    "        include_user_entities=False\n",
    "    ).items():\n",
    "        \n",
    "        json_data = item._json\n",
    "        \n",
    "        found_following = {}\n",
    "        found_following[\"id\"] = json_data[\"id\"]\n",
    "        found_following[\"name\"] = json_data[\"name\"]\n",
    "        found_following[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "        found_following[\"location\"] = json_data[\"location\"]\n",
    "        \n",
    "        if found_following not in followings_of_user:\n",
    "            followings_of_user.append(found_following)\n",
    "            \n",
    "    followings = followings_of_user\n",
    "    print(f\"Found {len(followings)} followings for user {user}\")\n",
    "    serialize_json(f\"{data_folder}/Following\", f\"{user}_followings.json\", followings)  #salva in un file .json tutti i folliwings del prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uniamo i file json in un unico file json che contiene i follower di tutti 5 professori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = [\"@mizzaro\", \"@damiano10\", \"@Miccighel_\", \"@eglu81\", \"@KevinRoitero\"]\n",
    "\n",
    "all_followers = {}\n",
    "temp = []\n",
    "\n",
    "for user in prof:\n",
    "    file = read_json(f\"{data_folder}/Follower/{user}_followers.json\")\n",
    "    temp.extend(file)\n",
    "\n",
    "all_followers = temp\n",
    "serialize_json(f\"{data_folder}/Follower\",\"all_prof_followers.json\",all_followers)   #tutti follower sono nel file all_prof_followers.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uniamo i file json in un unico file json che contiene i followings di tutti 5 professori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"@mizzaro\", \"@damiano10\", \"@Miccighel_\", \"@eglu81\", \"@KevinRoitero\"]\n",
    "\n",
    "all_followings = {}\n",
    "temp = []\n",
    "\n",
    "for user in users:\n",
    "    file = read_json(f\"{data_folder}/Following/{user}_followings.json\")\n",
    "    temp.extend(file)\n",
    "    \n",
    "all_followings = temp\n",
    "serialize_json(f\"{data_folder}/Following\",\"all_prof_followings.json\",all_followings)  #tutti followings sono nel file all_prof_followers.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scegliete 5 utenti followers a caso tra quelli di ciascuno dei cinque account e scaricate ulteriori 10 utenti followers (followers dei followers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dalla lista di ogni prof prende 5 random follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"@mizzaro\", \"@damiano10\", \"@Miccighel_\", \"@eglu81\", \"@KevinRoitero\"]\n",
    "all_random = {}\n",
    "random_followers = []\n",
    "for user in users:\n",
    "    \n",
    "    followers_user = read_json(f\"{data_folder}/Follower/{user}_followers.json\")\n",
    "    \n",
    "    count = len(followers_user)\n",
    "\n",
    "    for i in range (5):\n",
    "        num = randint(0,count)\n",
    "        single_random_follower = (followers_user[num])\n",
    "        random_followers.append(single_random_follower)\n",
    "        \n",
    "all_random = random_followers        \n",
    "        \n",
    "serialize_json(f\"{data_folder}/Random follower\", \"random_name.json\", all_random) #random_name.json contiene i random follower dei prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per ognuno dei random follower scarica 10 follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_name = read_json(f\"{data_folder}/Random Follower/random_name.json\")\n",
    "\n",
    "followers_of_random = []\n",
    "\n",
    "for random in random_name:\n",
    "        \n",
    "        print(f\"Processing random User {random['screen_name']}\")\n",
    "\n",
    "        for item in tweepy.Cursor(\n",
    "            api.followers, \n",
    "            screen_name=random['screen_name'], \n",
    "            skip_status=True, \n",
    "            include_user_entities=False\n",
    "        ).items(10):\n",
    "\n",
    "            json_data = item._json\n",
    "\n",
    "            found_follower = {}\n",
    "            found_follower[\"id\"] = json_data[\"id\"]\n",
    "            found_follower[\"name\"] = json_data[\"name\"]\n",
    "            found_follower[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "            found_follower[\"location\"] = json_data[\"location\"]\n",
    "            \n",
    "            if found_follower not in followers_of_random:\n",
    "                followers_of_random.append(found_follower)\n",
    "\n",
    "serialize_json(f\"{data_folder}/Random follower\", \"followers_random.json\", followers_of_random)  #followers_random.json contiene i follower dei random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scegliete 5 utenti following a caso tra quelli di ciascuno dei cinque account e scaricate ulteriori 10 utenti following (following dei following)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dalla lista di ogni prof prende 5 random followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"@mizzaro\", \"@damiano10\", \"@Miccighel_\", \"@eglu81\", \"@KevinRoitero\"]\n",
    "all_random = {}\n",
    "random_followings = []\n",
    "for user in users:\n",
    "    \n",
    "    followings_user = read_json(f\"{data_folder}/Following/{user}_followings.json\")\n",
    "    \n",
    "    count = len(followings_user)\n",
    "\n",
    "    for i in range (5):\n",
    "        num = randint(0,count)\n",
    "        single_random_following = (followings_user[num])\n",
    "        random_followings.append(single_random_following)\n",
    "        \n",
    "all_random = random_followings        \n",
    "        \n",
    "serialize_json(f\"{data_folder}/Random following\", \"random_name.json\", all_random) #random_name.json contiene i random follower e followings dei prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per ognuno dei random followings scarica 10 followings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_name = read_json(f\"{data_folder}/Random Following/random_name.json\")\n",
    "\n",
    "followings_of_random = []\n",
    "\n",
    "for random in random_name:\n",
    "        \n",
    "        print(f\"Processing random User {random['screen_name']}\")\n",
    "\n",
    "        for item in tweepy.Cursor(\n",
    "            api.friends, \n",
    "            screen_name=random['screen_name'], \n",
    "            skip_status=True, \n",
    "            include_user_entities=False\n",
    "        ).items(10):\n",
    "\n",
    "            json_data = item._json\n",
    "\n",
    "            found_following = {}\n",
    "            found_following[\"id\"] = json_data[\"id\"]\n",
    "            found_following[\"name\"] = json_data[\"name\"]\n",
    "            found_following[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "            found_following[\"location\"] = json_data[\"location\"]\n",
    "            \n",
    "            if found_following not in followings_of_random:\n",
    "                followings_of_random.append(found_following)\n",
    "\n",
    "serialize_json(f\"{data_folder}/Random following\", \"followings_random.json\", followings_of_random)  #followings_random.json contiene i followings dei random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scaricare i dettagli del profilo di tutti gli utenti recuperati (api.get_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scarica i detagli dei profili dei prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\"@mizzaro\", \"@damiano10\", \"@Miccighel_\", \"@eglu81\", \"@KevinRoitero\"]\n",
    "\n",
    "prof = []\n",
    "for user in users:\n",
    "    \n",
    "    details = api.get_user(user)\n",
    "    json_data = details._json\n",
    "    profile_data = {}\n",
    "    profile_data[\"id\"] = json_data[\"id\"]\n",
    "    profile_data[\"name\"] = json_data[\"name\"]\n",
    "    profile_data[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "    profile_data[\"location\"] = json_data[\"location\"]\n",
    "    profile_data[\"description\"] = json_data[\"description\"]\n",
    "    profile_data[\"followers_count\"] = json_data[\"followers_count\"]\n",
    "    if profile_data not in prof:\n",
    "        prof.append(profile_data)\n",
    "    \n",
    "serialize_json(data_folder, \"details_prof.json\", prof)   #details_prof.json contiene i detagli degli account dei prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scarica i detagli dei follower dei prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = read_json(f\"{data_folder}/all_prof_followers.json\")\n",
    "follower = []\n",
    "\n",
    "for user in lista:\n",
    "    \n",
    "    id = user['id']\n",
    "    details = api.get_user(user_id = id)\n",
    "    json_data = details._json\n",
    "    profile_data = {}\n",
    "    profile_data[\"id\"] = json_data[\"id\"]\n",
    "    profile_data[\"name\"] = json_data[\"name\"]\n",
    "    profile_data[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "    profile_data[\"location\"] = json_data[\"location\"]\n",
    "    profile_data[\"description\"] = json_data[\"description\"]\n",
    "    profile_data[\"followers_count\"] = json_data[\"followers_count\"]\n",
    "    if profile_data not in follower\n",
    "        follower.append(profile_data)\n",
    "    \n",
    "serialize_json(data_folder, \"details_prof_followers.json\", follower) #details_prof_followers.json contiene i detagli dei follower dei prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scarica i detagli dei followings dei prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = read_json(f\"{data_folder}/all_prof_followings.json\")\n",
    "followings = []\n",
    "\n",
    "for user in lista:\n",
    "    \n",
    "    id = user['id']\n",
    "    details = api.get_user(user_id = id)\n",
    "    json_data = details._json\n",
    "    profile_data = {}\n",
    "    profile_data[\"id\"] = json_data[\"id\"]\n",
    "    profile_data[\"name\"] = json_data[\"name\"]\n",
    "    profile_data[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "    profile_data[\"location\"] = json_data[\"location\"]\n",
    "    profile_data[\"description\"] = json_data[\"description\"]\n",
    "    profile_data[\"followers_count\"] = json_data[\"followers_count\"]\n",
    "    if profile_data not in followings:\n",
    "        followings.append(profile_data)\n",
    "    \n",
    "serialize_json(data_folder, \"details_prof_followings.json\", followings) #details_prof_followings.json contiene detagli dei followings dei prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scarica i detagli dei follower dei random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = read_json(f\"{data_folder}/Random follower/followers_random.json\")\n",
    "\n",
    "details = []\n",
    "for user in users:\n",
    "    r = api.get_user(user['screen_name'])\n",
    "    json_data = r._json\n",
    "    profile_data = {}\n",
    "    profile_data[\"id\"] = json_data[\"id\"]\n",
    "    profile_data[\"name\"] = json_data[\"name\"]\n",
    "    profile_data[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "    profile_data[\"location\"] = json_data[\"location\"]\n",
    "    profile_data[\"description\"] = json_data[\"description\"]\n",
    "    profile_data[\"followers_count\"] = json_data[\"followers_count\"]\n",
    "    if profile_data not in details:\n",
    "        details.append(profile_data)\n",
    "    \n",
    "serialize_json(f\"{data_folder}/Random follower\", \"details_followers_random.json\", details)  #details_followers_random.json contiene i detagli\n",
    "                                                                                            #dei follower dei random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scarica i detagli dei followings dei random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = read_json(f\"{data_folder}/Random following/followings_random.json\")\n",
    "\n",
    "details = []\n",
    "for user in users:\n",
    "    r = api.get_user(user['screen_name'])\n",
    "    json_data = r._json\n",
    "    profile_data = {}\n",
    "    profile_data[\"id\"] = json_data[\"id\"]\n",
    "    profile_data[\"name\"] = json_data[\"name\"]\n",
    "    profile_data[\"screen_name\"] = json_data[\"screen_name\"]\n",
    "    profile_data[\"location\"] = json_data[\"location\"]\n",
    "    profile_data[\"description\"] = json_data[\"description\"]\n",
    "    profile_data[\"followers_count\"] = json_data[\"followers_count\"]\n",
    "    #if profile_data not in details:\n",
    "    details.append(profile_data)\n",
    "    \n",
    "serialize_json(f\"{data_folder}/Random following\", \"details_followings_random.json\", details)  #details_followings_random.json contiene i \n",
    "                                                                                              #detagli dei followings dei random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Costruite la rete sociale (grafo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Inserite l’id di ciascun utente come identificatore del nodo\n",
    "#### -Inserite i dettagli del profilo di ciascun utente come attributi del nodo\n",
    "#### -Per ogni nodo, aggiungete un attributo con il numero di follower individuati\n",
    "#### -Inserite i membri del vostro gruppo come attributi del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "#crea nodi per i professori \n",
    "prof = read_json(f\"{data_folder}/details_prof.json\")\n",
    "for nodo in prof:\n",
    "    graph.add_node(nodo['id'], name = nodo['name'], screen_name = nodo['screen_name'], location = nodo['location'], description = nodo['description'], followers_count = nodo['followers_count'])\n",
    "\n",
    "#crea nodi per i follower dei prof\n",
    "all_followers = read_json(f\"{data_folder}/Follower/details_all_followers.json\")\n",
    "for nodo in all_followers:\n",
    "    graph.add_node(nodo['id'], name = nodo['name'], screen_name = nodo['screen_name'], location = nodo['location'], description = nodo['description'], followers_count = nodo['followers_count'])\n",
    "\n",
    "#crea nodi per i followings dei prof\n",
    "all_followings = read_json(f\"{data_folder}/Following/details_all_followings.json\")\n",
    "for nodo in all_followings:\n",
    "    graph.add_node(nodo['id'], name = nodo['name'], screen_name = nodo['screen_name'], location = nodo['location'], description = nodo['description'], followers_count = nodo['followers_count'])\n",
    "    \n",
    "#crea nodi per i random follower\n",
    "followers_random = read_json(f\"{data_folder}/Random follower/details_followers_random.json\")\n",
    "for nodo in followers_random:\n",
    "    graph.add_node(nodo['id'], name = nodo['name'], screen_name = nodo['screen_name'], location = nodo['location'], description = nodo['description'], followers_count = nodo['followers_count'])\n",
    "    \n",
    "#crea nodi per i random followings    \n",
    "followings_random = read_json(f\"{data_folder}/Random following/details_followings_random.json\")\n",
    "for nodo in followings_random:\n",
    "    graph.add_node(nodo['id'], name = nodo['name'], screen_name = nodo['screen_name'], location = nodo['location'], description = nodo['description'], followers_count = nodo['followers_count'])\n",
    "\n",
    "graph.graph[\"members\"] = [\"Marco Tateo, Leonardo Scandino, Leo Baric, Matteo Palomba\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prima di creare gli archi uniamo i file json di tutti follower, following, random follower e random following in un unico file json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user = {}\n",
    "temp = []\n",
    "\n",
    "temp.extend(prof)\n",
    "temp.extend(all_followers)\n",
    "temp.extend(all_followings)\n",
    "temp.extend(followers_random)\n",
    "temp.extend(followings_random)\n",
    "\n",
    "\n",
    "all_user = temp\n",
    "\n",
    "serialize_json(data_folder, \"all_user.json\", all_user)   #all_user.json contiene tutti user scaricati "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Ogni arco rappresenta una relazione follows tra due utenti\n",
    "#### -La presenza della relazione va verificata tra tutti gli utenti scaricati ed i cinque account iniziali (api.show_friendship)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crea archi tra ogni prof e i suoi follower e following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = read_json(f\"{data_folder}/all_user.json\")     #anche qui potevamo fare un loop che automaticamente crea archi per tutti i prof\n",
    "                                                     #ma per questioni di tempo abbiamo diviso il lavoro tra i membri del gruppo\n",
    "#mizzaro -> 18932422\n",
    "#damiano-> 132646210\n",
    "#micchighel -> 15750573\n",
    "#eglu -> 19659370\n",
    "#kevin -> 3036907250\n",
    "\n",
    "for nodo in file:\n",
    "    try:        #try per evitare l'errore che ci veniva se uno dei due user era privato o ha terminato il suo profilo\n",
    "        friendship = api.show_friendship(source_id = \"18932422\", target_id = f\"{nodo['id']}\")\n",
    "        if (friendship[0].following) or (friendship[0].followed_by):\n",
    "            graph.add_edge(friendship[0].id , friendship[1].id)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "nx.write_gpickle(graph, \"data/graph_mizzaro.pkl\")     #graph_mizzaro.pkl contiene tutti gli nodi e solo gli archi tra mizzaro i suoi follower/followings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Un modo alternativo per creare gli archi tra i professori e i loro follower e following senza utilizzare api.show_friendship()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodo non utilizzato nel progetto\n",
    "#Scandisce i file json de follower e followings di ogni professore e crea archi \n",
    "\n",
    "#creazione archi per @eglu81\n",
    "follower = read_json(\"data/Follower/@eglu81_followers.json\")\n",
    "following = read_json(\"data/Following/@eglu81_followings.json\")\n",
    "\n",
    "for nodo in following:\n",
    "    graph.add_edge(19659370 , nodo['id'])\n",
    "\n",
    "for nodo in follower:\n",
    "    graph.add_edge(19659370  ,nodo['id'] )\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "\n",
    "#creazione archi per @KEvinRoitero\n",
    "follower = read_json(\"data/Follower/@KevinRoitero_followers.json\")\n",
    "following = read_json(\"data/Following/@KevinRoitero_followings.json\")\n",
    "\n",
    "for nodo in following:\n",
    "    graph.add_edge(3036907250 , nodo['id'])\n",
    "\n",
    "for nodo in follower:\n",
    "    graph.add_edge(3036907250  ,nodo['id'] )\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "\n",
    "#creazione archi per @Mizzaro\n",
    "follower = read_json(\"data/Follower/@Mizzaro_followers.json\")\n",
    "following = read_json(\"data/Following/@Mizzaro_followings.json\")\n",
    "\n",
    "for nodo in following:\n",
    "    graph.add_edge(18932422 , nodo['id'])\n",
    "\n",
    "for nodo in follower:\n",
    "    graph.add_edge(18932422  ,nodo['id'] )\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "\n",
    "#creazione archi per @damiano10\n",
    "follower = read_json(\"data/Follower/@damiano10_followers.json\")\n",
    "following = read_json(\"data/Following/@damiano10_followings.json\")\n",
    "\n",
    "for nodo in following:\n",
    "    graph.add_edge(132646210 , nodo['id'])\n",
    "\n",
    "for nodo in follower:\n",
    "    graph.add_edge(132646210  ,nodo['id'] )\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "\n",
    "#creazione archi per @Miccighel_\n",
    "follower = read_json(\"data/Follower/@Miccighel__followers.json\")\n",
    "following = read_json(\"data/Following/@Miccighel__followings.json\")\n",
    "\n",
    "for nodo in following:\n",
    "    graph.add_edge(15750573 , nodo['id'])\n",
    "\n",
    "for nodo in follower:\n",
    "    graph.add_edge(15750573  ,nodo['id'] )\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())\n",
    "\n",
    "nx.write_gpickle(graph, \"data/grafo_tutti_prof_.pkl\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crea archi tra i random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = read_json(f\"{data_folder}/all_user_random.json\")\n",
    "all_name_random = read_json(f\"{data_folder}/all_name_random.json\")\n",
    "\n",
    "My_array = all_name_random[0:10]               #nella lista all_name_random ci sono 50 user e qui abbiamo diviso il lavoro in 5 parti per \n",
    "                                               #velocizzare l'esecuzione\n",
    "for s_nodo in My_array:\n",
    "    for t_nodo in file:\n",
    "        try:          #try per evitare l'errore che ci veniva se uno dei due user era privato o ha terminato il suo profilo\n",
    "            friendship = api.show_friendship(source_id = f\"{s_nodo['id']}\", target_id = f\"{t_nodo['id']}\")\n",
    "            if (friendship[0].following) or (friendship[0].followed_by):\n",
    "                graph.add_edge(friendship[0].id , friendship[1].id)\n",
    "        except:\n",
    "            pass\n",
    "                       \n",
    "nx.write_gpickle(graph, \"data/graph_random_0-10.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uniamo i grafi in un unico grafo con tutti nodi e archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphMizzaro = nx.read_gpickle(\"data/graph_mizzaro.pkl\")\n",
    "graph.add_edges_from(graphMizzaro.edges)\n",
    "\n",
    "graphDamiano = nx.read_gpickle(\"data/graph_damiano10.pkl\")\n",
    "graph.add_edges_from(graphDamiano.edges)\n",
    "\n",
    "graphMiccighel = nx.read_gpickle(\"data/graph_micchighel.pkl\")\n",
    "graph.add_edges_from(graphMiccighel.edges)\n",
    "\n",
    "graphEglu = nx.read_gpickle(\"data/graph_eglu.pkl\")\n",
    "graph.add_edges_from(graphEglu.edges)\n",
    "\n",
    "graphKevin = nx.read_gpickle(\"data/graph_kevin.pkl\")\n",
    "graph.add_edges_from(graphKevin.edges)\n",
    "\n",
    "graph0_10 = nx.read_gpickle(f\"{data_folder}/graph_random_1-10.pkl\")\n",
    "graph.add_edges_from(graph0_10.edges)\n",
    "\n",
    "graph10_20 = nx.read_gpickle(f\"{data_folder}/graph_random_10-20.pkl\")\n",
    "graph.add_edges_from(graph10_20.edges)\n",
    "\n",
    "graph20_30 = nx.read_gpickle(f\"{data_folder}/graph_random_20-30.pkl\")\n",
    "graph.add_edges_from(graph20_30.edges)\n",
    "\n",
    "graph30_33 = nx.read_gpickle(f\"{data_folder}/graph_random_30-33.pkl\")\n",
    "graph.add_edges_from(graph30_33.edges)\n",
    "\n",
    "graph33_36 = nx.read_gpickle(f\"{data_folder}/graph_random_33-36.pkl\")\n",
    "graph.add_edges_from(graph33_36.edges)\n",
    "\n",
    "graph36_40 = nx.read_gpickle(f\"{data_folder}/graph_random_36-40.pkl\")\n",
    "graph.add_edges_from(graph36_40.edges)\n",
    "\n",
    "graph40_50 = nx.read_gpickle(f\"{data_folder}/graph_random_40-50.pkl\")\n",
    "graph.add_edges_from(graph40_50.edges)\n",
    "\n",
    "nx.write_gpickle(graph, f\"{data_folder}/final_graph.pkl\")     #raccolto tutti gli archi in un unico grafo lo salviamo in final_graph.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alcuni nodi risultano isolati a causa del try/except percio a questo puno li rimuoviamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.remove_nodes_from(list(nx.isolates(graph)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Producete una visualizzazione interattiva del grafo usando pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = Network( #per pagina html\n",
    "    height=\"100%\", \n",
    "    width=\"100%\", \n",
    "    bgcolor=\"#222222\", \n",
    "    font_color=\"white\",\n",
    "    heading=\"final_graph\"\n",
    ")\n",
    "nt.barnes_hut() #prepara il layout 3D\n",
    "nt.from_nx(final_graph) \n",
    "neighbor_map = nt.get_adj_list() #lista di adiacenza, vicinato\n",
    "for node in nt.nodes:\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]]) #imposto il peso del nodo\n",
    "\n",
    "\n",
    "nt.show(\"final_graph_view.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Verificate se il grafo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -è connesso (is_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (nx.is_connected(final_graph)):\n",
    "    print(\"Questo grafo è connesso\")\n",
    "else:\n",
    "    print(\"Questo grafo NON è connesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -è bipartito (is_bipartite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (nx.is_bipartite(final_graph)):\n",
    "    print(\"Questo grafo è bipartito\")\n",
    "else:\n",
    "    print(\"Questo grafo NON è bipartito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Misurate le seguenti distanze sul grafo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Centro (center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = nx.center(final_graph)\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Diametro (diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = nx.diameter(final_graph)\n",
    "print(diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Raggio (radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = nx.radius(final_graph)\n",
    "print(radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Calcolate le seguenti misure di centralità sul grafo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Betweenness centrality (betweenness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_cent = nx.betweenness_centrality(final_graph)\n",
    "\n",
    "draw(\n",
    "    final_graph, \n",
    "    nx.spring_layout(final_graph), \n",
    "    nx.betweenness_centrality(final_graph), \n",
    "    'Betweenness Centrality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Closeness centrality (closeness_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clo_cent = nx.closeness_centrality(final_graph)\n",
    "\n",
    "draw(\n",
    "    final_graph, \n",
    "    nx.spring_layout(final_graph), \n",
    "    nx.closeness_centrality(final_graph), \n",
    "    'closeness_centrality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Degree centrality (degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_cent = nx.degree_centrality(final_graph)\n",
    "\n",
    "draw(\n",
    "    final_graph, \n",
    "    nx.spring_layout(final_graph), \n",
    "    nx.degree_centrality(final_graph), \n",
    "    'Degree Centrality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -In-degree centrality (in_degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_graph_direct = final_graph.to_directed()   #per calcolare la in e out degree centrality il grafo deve essere diretto\n",
    "\n",
    "in_deg_cent = nx.in_degree_centrality(final_graph_direct)\n",
    "\n",
    "draw(\n",
    "    final_graph_direct, \n",
    "    nx.spring_layout(final_graph_direct), \n",
    "    nx.in_degree_centrality(final_graph_direct), \n",
    "    'In Degree Centrality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Out-degree centrality (out_degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_deg_cent = nx.out_degree_centrality(final_graph_direct)\n",
    "\n",
    "draw(\n",
    "    final_graph_direct, \n",
    "    nx.spring_layout(final_graph_direct), \n",
    "    nx.in_degree_centrality(final_graph_direct), \n",
    "    'Out Degree Centrality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Page Rank (pagerank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank = nx.pagerank(final_graph_direct)\n",
    "\n",
    "draw(\n",
    "    final_graph_direct, \n",
    "    nx.spring_layout(final_graph_direct), \n",
    "    nx.pagerank(final_graph_direct), \n",
    "    'Page Rank'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -HITS (hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = nx.hits(final_graph_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Generate un sottografo del grafo (ego_graph) e calcolate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kevin_graph = nx.ego_graph(final_graph, 3036907250, radius=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Impostazioni per la visualizzazione del sottografo di Kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = []\n",
    "for node in kevin_graph:\n",
    "       if node  == 3036907250:\n",
    "            color_map.append('red')\n",
    "       else:\n",
    "            color_map.append('black')  \n",
    "        \n",
    "d = dict(kevin_graph.degree)\n",
    "\n",
    "rcParams['figure.figsize'] = 20, 20 \n",
    "nx.draw_networkx(\n",
    "    kevin_graph, \n",
    "    pos=nx.spring_layout(kevin_graph),\n",
    "    node_color= color_map,\n",
    "    edge_color=\"#a9a9a9\",\n",
    "    edge_cmap=plt.cm.Blues,\n",
    "    node_size = [v * 30 for v in d.values()],\n",
    "    alpha = 0.5,\n",
    "    width=1,\n",
    "    with_labels= False\n",
    ")\n",
    "\n",
    "plt.savefig(f\"{data_folder}/Kevin_graph.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cricca massima (max_clique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cl = clique.max_clique(kevin_graph)\n",
    "clique_subgraph = kevin_graph.subgraph(max_cl) \n",
    "layout = nx.spring_layout(kevin_graph)\n",
    "nx.draw_networkx(clique_subgraph, pos=layout)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Dimensione della cricca massima (large_clique_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_clique_size = clique.large_clique_size(kevin_graph)\n",
    "print(large_clique_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Calcolate la copertura minima degli archi (min_edge_cover) del grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_edge_cover = nx.min_edge_cover(final_graph)\n",
    "print(min_edge_cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Calcolate i seguenti coefficienti per stimare la “small-world-ness” del grafo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Coefficiente omega (omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = nx.omega(final_graph, niter = 10, nrand = 3)\n",
    "print(omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -Coefficiente sigma (sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = nx.sigma(final_graph, niter = 10, nrand = 3)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Calcolare la correlazione di Pearson Rho e di Kendall Tau fra le misure di centralità; riportare il risultato in due tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralità = [bet_cent, clo_cent, deg_cent, in_deg_cent, out_deg_cent, page_rank, hits[0], hits[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficienti di Pearson Rho\n",
    "pears_coef_values = []\n",
    "for i in range (8):\n",
    "    for t in range (8):\n",
    "        if t > i:\n",
    "            val = scipy.stats.pearsonr(list(centralità[i].values()), list(centralità[t].values()))\n",
    "            pears_coef_values.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficienti di Kendall Tau\n",
    "kendal_coef_values = []\n",
    "for i in range (8):\n",
    "    for t in range (8):\n",
    "        if t > i:\n",
    "            val = scipy.stats.kendalltau(list(centralità[i].values()), list(centralità[t].values()))\n",
    "            kendal_coef_values.append(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
